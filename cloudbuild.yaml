# CIPHER Platform - Production Cloud Build Configuration
# Service Account: cloud-build-service@primal-chariot-382610.iam.gserviceaccount.com

timeout: 1800s  # 30 minutes timeout for complete deployment

steps:
  # Step 1: Validate environment and prerequisites
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "🛡️ CIPHER Platform - Production Deployment Starting"
        echo "=============================================="
        echo "Project ID: $PROJECT_ID"
        echo "Build ID: $BUILD_ID"
        echo "Service Account: cloud-build-service@$PROJECT_ID.iam.gserviceaccount.com"
        echo "Timestamp: $$(date)"
        echo ""
        
        # Validate required APIs are enabled
        echo "🔍 Validating required APIs..."
        gcloud services list --enabled --filter="name:(run.googleapis.com OR cloudbuild.googleapis.com OR bigquery.googleapis.com)" --format="value(name)" | wc -l
        
        # Check service account permissions
        echo "🔑 Validating service account permissions..."
        gcloud projects get-iam-policy $PROJECT_ID \
          --flatten="bindings[].members" \
          --filter="bindings.members:cloud-build-service@$PROJECT_ID.iam.gserviceaccount.com" \
          --format="value(bindings.role)" | wc -l
        
        echo "✅ Pre-deployment validation completed"
    id: 'validate'

  # Step 2: Create BigQuery dataset
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "📊 Setting up BigQuery dataset..."
        
        # Create dataset if not exists
        if ! bq ls --project_id=$PROJECT_ID telegram_data >/dev/null 2>&1; then
          echo "Creating BigQuery dataset: telegram_data"
          bq mk --dataset \
            --location=US \
            --description="CIPHER Cybersecurity Intelligence Platform Data" \
            $PROJECT_ID:telegram_data
        else
          echo "✅ BigQuery dataset telegram_data already exists"
        fi
        
        echo "✅ BigQuery dataset setup completed"
    id: 'setup-dataset'
    waitFor: ['validate']

  # Step 3: Create enhanced schema file
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "🔧 Creating enhanced BigQuery schema..."
        
        # Create comprehensive enhanced schema
        cat > /tmp/cipher_enhanced_schema.json << 'EOF'
        [
          {"name": "message_id", "type": "STRING", "mode": "REQUIRED", "description": "Unique message identifier"},
          {"name": "chat_id", "type": "STRING", "mode": "REQUIRED", "description": "Telegram chat/channel ID"},
          {"name": "chat_username", "type": "STRING", "mode": "NULLABLE", "description": "Channel username (e.g., @DarkfeedNews)"},
          {"name": "user_id", "type": "STRING", "mode": "NULLABLE", "description": "Telegram user ID"},
          {"name": "username", "type": "STRING", "mode": "NULLABLE", "description": "Username without @ symbol"},
          {"name": "message_text", "type": "STRING", "mode": "NULLABLE", "description": "Original message content"},
          {"name": "message_date", "type": "TIMESTAMP", "mode": "REQUIRED", "description": "When message was sent"},
          {"name": "processed_date", "type": "TIMESTAMP", "mode": "REQUIRED", "description": "When message was processed"},
          
          {"name": "gemini_analysis", "type": "STRING", "mode": "NULLABLE", "description": "Gemini AI comprehensive threat analysis"},
          {"name": "sentiment", "type": "STRING", "mode": "NULLABLE", "description": "Message sentiment: positive/negative/neutral"},
          {"name": "confidence_score", "type": "FLOAT", "mode": "NULLABLE", "description": "AI analysis confidence (0.0-1.0)"},
          {"name": "key_topics", "type": "STRING", "mode": "REPEATED", "description": "Key cybersecurity topics identified"},
          {"name": "urgency_score", "type": "FLOAT", "mode": "NULLABLE", "description": "Threat urgency score (0.0-1.0)"},
          {"name": "category", "type": "STRING", "mode": "NULLABLE", "description": "Primary threat category"},
          {"name": "subcategory", "type": "STRING", "mode": "NULLABLE", "description": "Specific threat subcategory"},
          
          {"name": "threat_level", "type": "STRING", "mode": "NULLABLE", "description": "Threat level: critical/high/medium/low/info"},
          {"name": "threat_type", "type": "STRING", "mode": "NULLABLE", "description": "Specific threat type (e.g., APT, ransomware)"},
          {"name": "attack_stage", "type": "STRING", "mode": "NULLABLE", "description": "Attack lifecycle stage"},
          {"name": "kill_chain_phase", "type": "STRING", "mode": "NULLABLE", "description": "MITRE ATT&CK kill chain phase"},
          
          {"name": "channel_type", "type": "STRING", "mode": "NULLABLE", "description": "Source channel type"},
          {"name": "channel_priority", "type": "STRING", "mode": "NULLABLE", "description": "Channel priority level"},
          {"name": "channel_focus", "type": "STRING", "mode": "NULLABLE", "description": "Channel focus area"}
        ]
        EOF
        
        echo "✅ Enhanced schema file created"
    id: 'create-schema'
    waitFor: ['setup-dataset']

  # Step 4: Create enhanced schema file part 2 (IOCs and Intelligence)
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "🔧 Adding IOC and intelligence fields to schema..."
        
        # Append IOC and intelligence fields to schema
        cat >> /tmp/cipher_enhanced_schema.json << 'EOF'
        ,
          {"name": "iocs_detected", "type": "STRING", "mode": "REPEATED", "description": "All IOCs found"},
          {"name": "ip_addresses", "type": "STRING", "mode": "REPEATED", "description": "IP addresses found"},
          {"name": "domains", "type": "STRING", "mode": "REPEATED", "description": "Domains found"},
          {"name": "urls", "type": "STRING", "mode": "REPEATED", "description": "URLs found"},
          {"name": "file_hashes", "type": "STRING", "mode": "REPEATED", "description": "File hashes (MD5, SHA1, SHA256)"},
          {"name": "email_addresses", "type": "STRING", "mode": "REPEATED", "description": "Email addresses found"},
          
          {"name": "cve_references", "type": "STRING", "mode": "REPEATED", "description": "CVE references mentioned"},
          {"name": "cwe_references", "type": "STRING", "mode": "REPEATED", "description": "CWE references mentioned"},
          {"name": "mitre_techniques", "type": "STRING", "mode": "REPEATED", "description": "MITRE ATT&CK techniques"},
          {"name": "malware_families", "type": "STRING", "mode": "REPEATED", "description": "Malware families identified"},
          {"name": "threat_actors", "type": "STRING", "mode": "REPEATED", "description": "Threat actors/groups mentioned"},
          {"name": "campaign_names", "type": "STRING", "mode": "REPEATED", "description": "Campaign or operation names"},
          
          {"name": "affected_systems", "type": "STRING", "mode": "REPEATED", "description": "Systems/platforms affected"},
          {"name": "affected_vendors", "type": "STRING", "mode": "REPEATED", "description": "Vendors/companies affected"},
          {"name": "attack_vectors", "type": "STRING", "mode": "REPEATED", "description": "Attack vectors mentioned"},
          {"name": "vulnerabilities", "type": "STRING", "mode": "REPEATED", "description": "Vulnerability types"},
          {"name": "geographical_targets", "type": "STRING", "mode": "REPEATED", "description": "Geographic regions targeted"},
          {"name": "industry_targets", "type": "STRING", "mode": "REPEATED", "description": "Industries targeted"},
          
          {"name": "source_reliability", "type": "STRING", "mode": "NULLABLE", "description": "Source reliability assessment"},
          {"name": "information_type", "type": "STRING", "mode": "NULLABLE", "description": "Type of intelligence information"},
          {"name": "sharing_level", "type": "STRING", "mode": "NULLABLE", "description": "Information sharing level (TLP)"},
          {"name": "tags", "type": "STRING", "mode": "REPEATED", "description": "Custom tags for categorization"},
          
          {"name": "processing_time_ms", "type": "INTEGER", "mode": "NULLABLE", "description": "Processing time in milliseconds"},
          {"name": "data_quality_score", "type": "FLOAT", "mode": "NULLABLE", "description": "Data quality assessment (0.0-1.0)"},
          {"name": "false_positive_risk", "type": "STRING", "mode": "NULLABLE", "description": "False positive risk assessment"}
        ]
        EOF
        
        echo "✅ Complete enhanced schema file ready"
    id: 'complete-schema'
    waitFor: ['create-schema']

  # Step 5: Setup BigQuery table with enhanced schema
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "📊 Setting up enhanced BigQuery table..."
        
        # Check if table exists and get current schema
        TABLE_EXISTS=false
        CURRENT_FIELDS=0
        if bq ls --project_id=$PROJECT_ID telegram_data.processed_messages >/dev/null 2>&1; then
          TABLE_EXISTS=true
          CURRENT_FIELDS=$$(bq show --format=json $PROJECT_ID:telegram_data.processed_messages | jq '.schema.fields | length')
          echo "✅ Table exists with $$CURRENT_FIELDS fields"
        fi
        
        TARGET_FIELDS=$$(cat /tmp/cipher_enhanced_schema.json | jq '. | length')
        echo "Target schema has $$TARGET_FIELDS fields"
        
        if [ "$$TABLE_EXISTS" = "false" ]; then
          echo "Creating new enhanced BigQuery table..."
          bq mk --table \
            --description="CIPHER Cybersecurity Intelligence Messages - Enhanced Schema" \
            --time_partitioning_field=processed_date \
            --time_partitioning_type=DAY \
            --clustering_fields=threat_level,channel_type,category,threat_type \
            $PROJECT_ID:telegram_data.processed_messages \
            /tmp/cipher_enhanced_schema.json
          echo "✅ Created enhanced BigQuery table with $$TARGET_FIELDS fields"
        else
          echo "✅ Table exists with $$CURRENT_FIELDS fields"
        fi
        
        # Verify final schema
        FINAL_FIELDS=$$(bq show --format=json $PROJECT_ID:telegram_data.processed_messages | jq '.schema.fields | length')
        echo "✅ Final table has $$FINAL_FIELDS fields"
        
        # Cleanup
        rm -f /tmp/cipher_enhanced_schema.json
        
        echo "✅ Enhanced BigQuery infrastructure setup completed"
    id: 'setup-table'
    waitFor: ['complete-schema']

  # Step 6: Build Docker image
  - name: 'gcr.io/cloud-builders/docker'
    args: [
      'build',
      '--tag', 'gcr.io/$PROJECT_ID/telegram-ai-processor:$BUILD_ID',
      '--tag', 'gcr.io/$PROJECT_ID/telegram-ai-processor:latest',
      '--build-arg', 'PROJECT_ID=$PROJECT_ID',
      '--build-arg', 'BUILD_ID=$BUILD_ID',
      '.'
    ]
    id: 'build-image'
    waitFor: ['setup-table']

  # Step 7: Push Docker image to Container Registry
  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', '--all-tags', 'gcr.io/$PROJECT_ID/telegram-ai-processor']
    id: 'push-image'
    waitFor: ['build-image']

  # Step 8: Deploy to Cloud Run with production configuration
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'gcloud'
    args: [
      'run', 'deploy', 'telegram-ai-processor',
      '--image', 'gcr.io/$PROJECT_ID/telegram-ai-processor:$BUILD_ID',
      '--region', 'us-central1',
      '--platform', 'managed',
      '--allow-unauthenticated',
      '--service-account', 'cloud-build-service@$PROJECT_ID.iam.gserviceaccount.com',
      '--memory', '4Gi',
      '--cpu', '2',
      '--port', '8080',
      '--timeout', '3600',
      '--concurrency', '80',
      '--min-instances', '0',
      '--max-instances', '10',
      '--set-env-vars', 'GOOGLE_CLOUD_PROJECT=$PROJECT_ID,LOG_LEVEL=INFO,DATASET_ID=telegram_data,TABLE_ID=processed_messages,PYTHONUNBUFFERED=1',
      '--labels', 'app=cipher,environment=production,version=$BUILD_ID',
      '--no-cpu-throttling'
    ]
    id: 'deploy'
    waitFor: ['push-image']

  # Step 9: Configure IAM policies
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "⚙️ Configuring IAM policies..."
        
        # Set IAM policies for public access
        echo "Setting IAM policies for public access..."
        gcloud run services add-iam-policy-binding telegram-ai-processor \
          --region=us-central1 \
          --member="allUsers" \
          --role="roles/run.invoker"
        
        echo "✅ IAM configuration applied"
    id: 'configure'
    waitFor: ['deploy']

  # Step 10: Run health checks and verify deployment
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "🏥 Running deployment health checks..."
        
        # Get service URL
        DEPLOYED_URL=$$(gcloud run services describe telegram-ai-processor \
          --region=us-central1 \
          --project=$PROJECT_ID \
          --format='value(status.url)')
        
        if [ -z "$$DEPLOYED_URL" ]; then
          echo "❌ Failed to get service URL"
          exit 1
        fi
        
        echo "Service deployed at: $$DEPLOYED_URL"
        
        # Wait for service to be ready
        echo "Waiting for service to initialize..."
        sleep 45
        
        # Test health endpoints with retries
        echo "Testing health endpoints..."
        
        # Test liveness probe
        echo "Testing /health/live endpoint..."
        for i in {1..5}; do
          HEALTH_STATUS=$$(curl -s -o /dev/null -w "%{http_code}" "$$DEPLOYED_URL/health/live" || echo "000")
          if [ "$$HEALTH_STATUS" = "200" ]; then
            echo "✅ Liveness check: PASSED"
            break
          else
            echo "⚠️ Liveness check attempt $$i: HTTP $$HEALTH_STATUS"
            sleep 10
          fi
        done
        
        # Test readiness probe
        echo "Testing /health endpoint..."
        for i in {1..3}; do
          READY_STATUS=$$(curl -s -o /dev/null -w "%{http_code}" "$$DEPLOYED_URL/health" || echo "000")
          if [ "$$READY_STATUS" = "200" ]; then
            echo "✅ Readiness check: PASSED"
            break
          else
            echo "⚠️ Readiness check attempt $$i: HTTP $$READY_STATUS"
            sleep 15
          fi
        done
        
        # Test main dashboard
        echo "Testing main dashboard..."
        DASH_STATUS=$$(curl -s -o /dev/null -w "%{http_code}" "$$DEPLOYED_URL/dashboard" || echo "000")
        if [ "$$DASH_STATUS" = "200" ]; then
          echo "✅ Dashboard: PASSED"
        else
          echo "⚠️ Dashboard: HTTP $$DASH_STATUS"
        fi
        
        echo ""
        echo "🎉 CIPHER Platform Deployment Completed!"
        echo "======================================="
        echo "Service URL: $$DEPLOYED_URL"
        echo "Dashboard: $$DEPLOYED_URL/dashboard"
        echo "Health Check: $$DEPLOYED_URL/health"
        echo "Stats API: $$DEPLOYED_URL/api/stats"
        echo "Monitoring: $$DEPLOYED_URL/api/monitoring/status"
        echo ""
        echo "🔧 Technical Details:"
        echo "Project: $PROJECT_ID"
        echo "Build ID: $BUILD_ID"
        echo "Service Account: cloud-build-service@$PROJECT_ID.iam.gserviceaccount.com"
        echo "Region: us-central1"
        echo "Memory: 4Gi"
        echo "CPU: 2"
        echo "BigQuery Dataset: telegram_data (ENHANCED SCHEMA)"
        echo ""
        echo "📊 Schema Status:"
        FINAL_FIELDS=$$(bq show --format=json $PROJECT_ID:telegram_data.processed_messages | jq '.schema.fields | length')
        echo "BigQuery Table Fields: $$FINAL_FIELDS"
        echo "Schema Migration: COMPLETED"
        echo ""
        echo "📡 Monitoring Channels:"
        echo "🔴 @DarkfeedNews - Threat Intelligence"
        echo "🟠 @breachdetector - Data Breach Monitor"  
        echo "🔵 @secharvester - Security News"
        echo ""
        echo "🛡️ CIPHER Platform is now operational with enhanced analytics!"
    id: 'verify'
    waitFor: ['configure']

  # Step 11: Generate deployment report
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "📋 Generating enhanced deployment report..."
        
        # Service status
        echo ""
        echo "🔍 Service Status:"
        gcloud run services describe telegram-ai-processor \
          --region=us-central1 \
          --project=$PROJECT_ID \
          --format='table(status.conditions[].type,status.conditions[].status,status.conditions[].reason)'
        
        # Service configuration
        echo ""
        echo "⚙️ Service Configuration:"
        gcloud run services describe telegram-ai-processor \
          --region=us-central1 \
          --project=$PROJECT_ID \
          --format='table(spec.template.spec.containers[].resources.limits.memory,spec.template.spec.containers[].resources.limits.cpu,spec.template.spec.serviceAccountName)'
        
        # Enhanced BigQuery dataset status
        echo ""
        echo "📊 BigQuery Enhanced Status:"
        bq show --format=prettyjson $PROJECT_ID:telegram_data | grep -E '"datasetId"|"location"|"description"' || true
        
        # Table schema verification
        echo ""
        echo "🗃️ Table Schema Status:"
        FIELD_COUNT=$$(bq show --format=json $PROJECT_ID:telegram_data.processed_messages | jq '.schema.fields | length')
        echo "Total Fields: $$FIELD_COUNT"
        echo "Partitioning: DAY (processed_date)"
        echo "Clustering: threat_level, channel_type, category, threat_type"
        
        echo ""
        echo "✅ Enhanced deployment report generated successfully"
        echo "📝 Build completed with BigQuery schema enhancement at: $$(date)"
    id: 'report'
    waitFor: ['verify']

# Required options for service account builds
options:
  logging: CLOUD_LOGGING_ONLY
  machineType: 'E2_HIGHCPU_8'
  diskSizeGb: 100
  substitution_option: 'ALLOW_LOOSE'

# Images to be pushed to Container Registry
images:
  - 'gcr.io/$PROJECT_ID/telegram-ai-processor:$BUILD_ID'
  - 'gcr.io/$PROJECT_ID/telegram-ai-processor:latest'
